{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1x4m_WV2TSL"
   },
   "source": [
    "## **Development of a QnA Chatbot for Interaction with a Tabular Dataset**\n",
    "\n",
    "### **Objective:**\n",
    "\n",
    "To create a question and answer (QnA) chatbot capable of interacting with a given pollution dataset in .csv format.\n",
    "\n",
    "### **Task:**\n",
    "\n",
    "1. Use any suitable RAG method to extract relevant information from the data.\n",
    "2. Develop two versions of the chatbot:\n",
    "  * List Template Based Chatbot\n",
    "  * Text Template Based Chatbot\n",
    "  \n",
    "  Both versions of the chatbot should be able to interpret and respond to user queries using the\n",
    "data from the pollution dataset.\n",
    "3. Use any Large Language Model to generate responses based on the data extracted from the\n",
    "table.\n",
    "\n",
    "### **User Instructions:**\n",
    "1.\tThe python file is in Notebook format (.ipynb). The file can be run using `Google Colab`.\n",
    "2.\tGo to Colab, click `upload notebook` and upload the notebook file.\n",
    "3.\tNext step is to upload the CSV file that needed to generated from. Upload the document in /content/ folder.\n",
    "4.\tChange the `query` variable accordingly.\n",
    "5.\tRun the cells by clicking `runtime -> run all`. This will all the cells and gives the output of each cell.\n",
    "\n",
    "### **Implementation Details**:\n",
    "\n",
    "1.\t**Import necessary libraries:** The first step of our implementation is to install and import all the necessary libraries that we need. The libraries that are used are: `pandas`, `sklearn`, and `Groq`.\n",
    "2.\t**Load and Vectorize CSV data:** Load the CSV data and Vectorize it for both the list and text template using pandas and `TfidfVectorizer`class.\n",
    "3.\t**Perform Similarity Search:** Next step is to perform similarity search according to the given query on both the list and text template.\n",
    "5.\t**Generating Answer:** The retrieved content along with the user query for both list and text template is used seperatly as input to generate seperate answers using the `llama2-70b-4096` model which we can use from `Groq` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd8_AE7K6Sae"
   },
   "source": [
    "## **Code Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZcLVvzx6Yxr"
   },
   "source": [
    "### **Installing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz6y_SorKjPO"
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fylCp_6Q6gN4"
   },
   "source": [
    "### **Importing all neccessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "o3rmQhoLPUDp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from groq import Groq\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62SU-7Sf6ruy"
   },
   "source": [
    "### **Defining query that we need to perform from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "g43R_X6ipU_H"
   },
   "outputs": [],
   "source": [
    "query = \"Which city in Myanmar has good AQI value?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln9oMevY7quk"
   },
   "source": [
    "### **Vectorizing and performing Similarity Search over list template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "l7shePj-1RNZ"
   },
   "outputs": [],
   "source": [
    "# Reading and converting the dataset into pandas DataFrame\n",
    "df = pd.read_csv(\"pollution_dataset.csv\")\n",
    "\n",
    "# converting DF to List of dictionaries\n",
    "list_template = df.to_dict(orient='records')\n",
    "\n",
    "# creating new key with name `text` which concatinates all the row values\n",
    "df['text'] = df.apply(lambda row: ' '.join(map(str, row.values)), axis=1)\n",
    "\n",
    "# Vectorizing the DF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Function that perform Similarity search and return the of data that matches the query\n",
    "def find_best_matches(query, k=5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarity_scores = cosine_similarity(query_vec, X).flatten()\n",
    "    best_match_indices = similarity_scores.argsort()[-k:][::-1]\n",
    "    return [list_template[i] for i in best_match_indices]\n",
    "\n",
    "# storing the list of result got from the function for list template to a variable\n",
    "best_matches = find_best_matches(query)\n",
    "best_matches_list_template = ' '.join(map(str, best_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODWqDnjP75o2"
   },
   "source": [
    "### **Vectorizing and performing Similarity Search over text template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "ypO1UOga39uv"
   },
   "outputs": [],
   "source": [
    "# Iterating over the list template and converting the dictionary into text\n",
    "text_template = []\n",
    "for row_dict in list_template:\n",
    "    text_template.append(f\"In {row_dict['City']}, {row_dict['Country']}, the AQI Value is {row_dict['AQI Value']} and falls under the category {row_dict['AQI Category']}. The CO AQI Value is {row_dict['CO AQI Value']} ({row_dict['CO AQI Category']}), Ozone AQI Value is {row_dict['Ozone AQI Value']} ({row_dict['Ozone AQI Category']}), NO2 AQI Value is {row_dict['NO2 AQI Value']} ({row_dict['NO2 AQI Category']}), and PM2.5 AQI Value is {row_dict['PM2.5 AQI Value']} ({row_dict['PM2.5 AQI Category']}).\")\n",
    "\n",
    "# Same process that we have done for list template\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(text_template)\n",
    "\n",
    "def find_best_matches(query, k=5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarity_scores = cosine_similarity(query_vec, X).flatten()\n",
    "    best_match_indices = similarity_scores.argsort()[-k:][::-1]\n",
    "    return [text_template[i] for i in best_match_indices]\n",
    "\n",
    "# storing the list of result got from the function for text template to a variable\n",
    "best_matches = find_best_matches(query)\n",
    "best_matches_text_template = ' '.join(best_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUivnogJ9dZX"
   },
   "source": [
    "### **Generating response for date returned from text template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1h8d1U_XHCU",
    "outputId": "061c12be-52bd-499a-fdd4-9050a181e3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help you with that!\n",
      "\n",
      "Based on the given information, all the cities mentioned - Taunggyi, Ye, Labutta, Pathein, and Pyapon - have good AQI values, with the PM2.5 AQI value ranging from 30 to 39, which falls under the \"Good\" category.\n",
      "\n",
      "Therefore, all five cities in Myanmar mentioned in the context have good AQI values."
     ]
    }
   ],
   "source": [
    "# setting environment variable for groq\n",
    "os.environ['GROQ_API_KEY'] = 'your Groq API Key Here'\n",
    "\n",
    "prompt = f'''You are a chatbot you must generate a good summarised answer from the given context.\n",
    "    Use the following provided context to answer the query enclosed within triple backticks.\n",
    "    Context: {best_matches_text_template}\n",
    "    User Query: ```{query}```\n",
    "    Answer:\n",
    "'''\n",
    "\n",
    "# creating groq client to use the model `llama2-70b-4096`\n",
    "client = Groq()\n",
    "\n",
    "# generating answer from the context and query using 'llama2-70b-4096' model:\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama2-70b-4096\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\" {prompt}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "# printing the result\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P9qHdP-9qpH"
   },
   "source": [
    "### **Generating response for date returned from list template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hn3j5fEp0VW",
    "outputId": "dda24c79-faf0-44e6-87c7-f29ab003ca27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, both Taunggyi and Ye in Myanmar have good AQI values. The AQI value for Taunggyi is 39, which falls under the \"Good\" category, while Ye has an AQI value of 34, also categorized as \"Good\". Therefore, both cities can be considered as having good air quality. However, it's important to note that air quality can change over time and may vary depending on different locations within a city. It's always a good idea to check the current AQI value before planning outdoor activities."
     ]
    }
   ],
   "source": [
    "prompt = f'''You are a chatbot you must generate a good summarised answer from the given context.\n",
    "    Use the following provided context to answer the query enclosed within triple backticks.\n",
    "    Context: {best_matches_list_template}\n",
    "    User Query: ```{query}```\n",
    "    Answer:\n",
    "'''\n",
    "\n",
    "# creating groq client to use the model `llama2-70b-4096`\n",
    "client = Groq()\n",
    "\n",
    "# generating answer from the context and query using 'llama2-70b-4096' model:\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama2-70b-4096\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\" {prompt}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "# printing the result\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
